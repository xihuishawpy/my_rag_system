"""
æ£€ç´¢æ¨¡å—è¿è¡Œè„šæœ¬
æ¼”ç¤ºå’Œæµ‹è¯•æ£€ç´¢åŠŸèƒ½
"""
import sys
import os
import json
import time
from pathlib import Path
from typing import List, Dict, Any

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from retrieval import RetrievalEngine, QueryProcessor, RetrievalResult
from vector_store import VectorStoreManager
from embedding import EmbeddingEngine
from config import VECTOR_STORE_PATH, EXCEL_FILE_PATH, TOP_K, VECTOR_STORE_TYPE

def test_query_processing():
    """æµ‹è¯•æŸ¥è¯¢å¤„ç†åŠŸèƒ½"""
    print("=== æµ‹è¯•æŸ¥è¯¢å¤„ç† ===")
    
    processor = QueryProcessor()
    
    test_queries = [
        "é‡‘å±ææ–™æ‹‰ä¼¸å¼ºåº¦æµ‹è¯•",
        "å¡‘æ–™æˆåˆ†åˆ†æä»·æ ¼ä¸è¶…è¿‡300å…ƒ",
        "ç¯å¢ƒæ£€æµ‹CMAè®¤è¯å®éªŒå®¤",
        "æ©¡èƒ¶è€åŒ–è¯•éªŒå‘¨æœŸ7å¤©ä»¥å†…",
        "ä»€ä¹ˆæ˜¯é‡‘å±ç–²åŠ³æµ‹è¯•ï¼Ÿ",
        "æ¯”è¾ƒä¸åŒææ–™çš„ç¡¬åº¦æµ‹è¯•æ–¹æ³•"
    ]
    
    print("æŸ¥è¯¢åˆ†æç»“æœ:")
    print("-" * 80)
    
    for query in test_queries:
        analysis = processor.analyze_query(query)
        print(f"åŸå§‹æŸ¥è¯¢: {analysis.original_query}")
        print(f"å¤„ç†å: {analysis.processed_query}")
        print(f"ç±»å‹: {analysis.query_type} | æ„å›¾: {analysis.intent} | ç½®ä¿¡åº¦: {analysis.confidence:.2f}")
        print(f"å…³é”®è¯: {analysis.keywords}")
        if analysis.filters:
            print(f"è¿‡æ»¤æ¡ä»¶: {analysis.filters}")
        print("-" * 80)

def test_semantic_search(retrieval_engine: RetrievalEngine):
    """æµ‹è¯•è¯­ä¹‰æœç´¢"""
    print("\n=== æµ‹è¯•è¯­ä¹‰æœç´¢ ===")
    
    test_queries = [
        "é‡‘å±ææ–™åŠ›å­¦æ€§èƒ½æµ‹è¯•",
        "å¡‘æ–™åˆ¶å“æˆåˆ†æ£€æµ‹",
        "ç¯å¢ƒæ±¡æŸ“ç‰©æ£€æµ‹",
        "é£Ÿå“å®‰å…¨æ£€æµ‹é¡¹ç›®",
        "å»ºç­‘ææ–™å¼ºåº¦æµ‹è¯•"
    ]
    
    for query in test_queries:
        print(f"\næŸ¥è¯¢: {query}")
        start_time = time.time()
        
        results = retrieval_engine.semantic_search(query, top_k=5)
        
        duration = time.time() - start_time
        print(f"æœç´¢æ—¶é—´: {duration:.3f}ç§’")
        print(f"ç»“æœæ•°é‡: {len(results)}")
        
        if results:
            print("å‰3ä¸ªç»“æœ:")
            for i, result in enumerate(results[:3], 1):
                print(f"  {i}. åˆ†æ•°: {result.score:.4f}")
                print(f"     å†…å®¹: {result.document.content[:100]}...")
                if result.document.metadata:
                    sample_type = result.document.metadata.get('raw_æ ·å“ç±»åˆ«', 'N/A')
                    test_item = result.document.metadata.get('raw_æµ‹è¯•é¡¹ç›®', 'N/A')
                    print(f"     æ ·å“ç±»åˆ«: {sample_type} | æµ‹è¯•é¡¹ç›®: {test_item}")
                print()

def test_hybrid_search(retrieval_engine: RetrievalEngine):
    """æµ‹è¯•æ··åˆæœç´¢"""
    print("\n=== æµ‹è¯•æ··åˆæœç´¢ ===")
    
    test_queries = [
        "é‡‘å±æ‹‰ä¼¸å¼ºåº¦æµ‹è¯•æ–¹æ³•",
        "å¡‘æ–™ææ–™è€åŒ–æ€§èƒ½æ£€æµ‹",
        "ç¯å¢ƒæ°´è´¨é‡é‡‘å±åˆ†æ"
    ]
    
    alphas = [0.3, 0.5, 0.7, 0.9]  # ä¸åŒçš„è¯­ä¹‰æƒé‡
    
    for query in test_queries:
        print(f"\næŸ¥è¯¢: {query}")
        
        for alpha in alphas:
            start_time = time.time()
            results = retrieval_engine.hybrid_search(query, top_k=3, alpha=alpha)
            duration = time.time() - start_time
            
            print(f"  Î±={alpha} | æ—¶é—´: {duration:.3f}ç§’ | ç»“æœæ•°: {len(results)}")
            
            if results:
                best_result = results[0]
                print(f"    æœ€ä½³: {best_result.document.content[:80]}... (åˆ†æ•°: {best_result.score:.4f})")
                if best_result.metadata:
                    semantic_score = best_result.metadata.get('semantic_score', 0)
                    keyword_score = best_result.metadata.get('keyword_score', 0)
                    print(f"    è¯­ä¹‰: {semantic_score:.4f} | å…³é”®è¯: {keyword_score:.4f}")

def test_filtered_search(retrieval_engine: RetrievalEngine):
    """æµ‹è¯•è¿‡æ»¤æœç´¢"""
    print("\n=== æµ‹è¯•è¿‡æ»¤æœç´¢ ===")
    
    test_cases = [
        {
            "query": "ææ–™å¼ºåº¦æµ‹è¯•",
            "filters": {"sample_category": "é‡‘å±"},
            "description": "é‡‘å±ç±»ææ–™"
        },
        {
            "query": "æˆåˆ†åˆ†æ",
            "filters": {"CMA": True},
            "description": "CMAè®¤è¯"
        },
        {
            "query": "ç¯å¢ƒæ£€æµ‹",
            "filters": {"CNAS": True},
            "description": "CNASè®¤å¯"
        }
    ]
    
    for case in test_cases:
        print(f"\næµ‹è¯•æ¡ˆä¾‹: {case['description']}")
        print(f"æŸ¥è¯¢: {case['query']}")
        print(f"è¿‡æ»¤æ¡ä»¶: {case['filters']}")
        
        start_time = time.time()
        results = retrieval_engine.filtered_search(case['query'], case['filters'], top_k=5)
        duration = time.time() - start_time
        
        print(f"æœç´¢æ—¶é—´: {duration:.3f}ç§’")
        print(f"ç»“æœæ•°é‡: {len(results)}")
        
        if results:
            print("ç»“æœé¢„è§ˆ:")
            for i, result in enumerate(results[:3], 1):
                print(f"  {i}. {result.document.content[:80]}...")
                print(f"     åˆ†æ•°: {result.score:.4f}")
                
                # éªŒè¯è¿‡æ»¤æ¡ä»¶
                metadata = result.document.metadata
                if metadata:
                    if 'sample_category' in case['filters']:
                        actual_category = metadata.get('raw_æ ·å“ç±»åˆ«', 'N/A')
                        print(f"     æ ·å“ç±»åˆ«: {actual_category}")
                    if case['filters'].get('CMA'):
                        cma_status = metadata.get('raw_CMA', 'N/A')
                        print(f"     CMAè®¤è¯: {cma_status}")
                    if case['filters'].get('CNAS'):
                        cnas_status = metadata.get('raw_CNAS', 'N/A')
                        print(f"     CNASè®¤å¯: {cnas_status}")

def test_multi_query_search(retrieval_engine: RetrievalEngine):
    """æµ‹è¯•å¤šæŸ¥è¯¢èåˆæœç´¢"""
    print("\n=== æµ‹è¯•å¤šæŸ¥è¯¢èåˆæœç´¢ ===")
    
    test_cases = [
        {
            "queries": ["é‡‘å±æµ‹è¯•", "åŠ›å­¦æ€§èƒ½", "å¼ºåº¦æ£€æµ‹"],
            "description": "é‡‘å±åŠ›å­¦æ€§èƒ½ç›¸å…³"
        },
        {
            "queries": ["å¡‘æ–™æ£€æµ‹", "æˆåˆ†åˆ†æ", "ç‰©ç†æ€§èƒ½"],
            "description": "å¡‘æ–™æ£€æµ‹ç›¸å…³"
        },
        {
            "queries": ["ç¯å¢ƒç›‘æµ‹", "æ°´è´¨æ£€æµ‹", "æ±¡æŸ“ç‰©åˆ†æ"],
            "description": "ç¯å¢ƒæ£€æµ‹ç›¸å…³"
        }
    ]
    
    fusion_methods = ["rrf", "weighted", "max"]
    
    for case in test_cases:
        print(f"\næµ‹è¯•æ¡ˆä¾‹: {case['description']}")
        print(f"æŸ¥è¯¢åˆ—è¡¨: {case['queries']}")
        
        for method in fusion_methods:
            start_time = time.time()
            results = retrieval_engine.multi_query_search(
                case['queries'], 
                top_k=5, 
                fusion_method=method
            )
            duration = time.time() - start_time
            
            print(f"  èåˆæ–¹æ³•: {method} | æ—¶é—´: {duration:.3f}ç§’ | ç»“æœæ•°: {len(results)}")
            
            if results:
                best_result = results[0]
                print(f"    æœ€ä½³ç»“æœ: {best_result.document.content[:60]}...")
                print(f"    åˆ†æ•°: {best_result.score:.4f}")

def test_smart_search(retrieval_engine: RetrievalEngine):
    """æµ‹è¯•æ™ºèƒ½æœç´¢"""
    print("\n=== æµ‹è¯•æ™ºèƒ½æœç´¢ ===")
    
    test_queries = [
        "ææ–™æµ‹è¯•",  # ç®€å•æŸ¥è¯¢
        "é‡‘å±ææ–™æ‹‰ä¼¸å¼ºåº¦æµ‹è¯•ä»·æ ¼ä¸è¶…è¿‡500å…ƒ",  # å¸¦è¿‡æ»¤æ¡ä»¶
        "ä»€ä¹ˆæ˜¯å¡‘æ–™è€åŒ–è¯•éªŒï¼Œå¦‚ä½•è¿›è¡Œæµ‹è¯•ï¼Œå‘¨æœŸå¤šé•¿ï¼Ÿ",  # å¤æ‚æŸ¥è¯¢
        "ç¯å¢ƒæ£€æµ‹CMAè®¤è¯å®éªŒå®¤",  # å¸¦è®¤è¯è¦æ±‚
        "æ¯”è¾ƒä¸åŒææ–™çš„ç¡¬åº¦æµ‹è¯•æ–¹æ³•å’Œæ ‡å‡†"  # æ¯”è¾ƒç±»æŸ¥è¯¢
    ]
    
    for query in test_queries:
        print(f"\næŸ¥è¯¢: {query}")
        
        start_time = time.time()
        results = retrieval_engine.smart_search(query, top_k=3)
        duration = time.time() - start_time
        
        print(f"æœç´¢æ—¶é—´: {duration:.3f}ç§’")
        print(f"ç»“æœæ•°é‡: {len(results)}")
        
        if results:
            first_result = results[0]
            print(f"ç­–ç•¥: {first_result.retrieval_type}")
            print(f"æœ€ä½³ç»“æœ: {first_result.document.content[:100]}...")
            print(f"åˆ†æ•°: {first_result.score:.4f}")
            
            # æ˜¾ç¤ºæŸ¥è¯¢åˆ†æä¿¡æ¯
            if first_result.metadata and 'query_analysis' in first_result.metadata:
                analysis = first_result.metadata['query_analysis']
                print(f"æŸ¥è¯¢åˆ†æ: ç±»å‹={analysis['query_type']}, æ„å›¾={analysis['intent']}, ç½®ä¿¡åº¦={analysis['confidence']:.2f}")

def benchmark_retrieval_performance(retrieval_engine: RetrievalEngine):
    """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    print("\n=== æ£€ç´¢æ€§èƒ½åŸºå‡†æµ‹è¯• ===")
    
    # ä¸åŒå¤æ‚åº¦çš„æŸ¥è¯¢
    benchmark_queries = {
        "ç®€å•æŸ¥è¯¢": [
            "é‡‘å±æµ‹è¯•", "å¡‘æ–™æ£€æµ‹", "ç¯å¢ƒç›‘æµ‹", "é£Ÿå“æ£€éªŒ", "å»ºææ£€æµ‹"
        ],
        "ä¸­ç­‰æŸ¥è¯¢": [
            "é‡‘å±ææ–™åŠ›å­¦æ€§èƒ½æµ‹è¯•", "å¡‘æ–™åˆ¶å“æˆåˆ†åˆ†æ", "ç¯å¢ƒæ°´è´¨æ±¡æŸ“ç‰©æ£€æµ‹",
            "é£Ÿå“æ·»åŠ å‰‚å®‰å…¨æ£€éªŒ", "å»ºç­‘ææ–™å¼ºåº¦æµ‹è¯•"
        ],
        "å¤æ‚æŸ¥è¯¢": [
            "é‡‘å±ææ–™æ‹‰ä¼¸å¼ºåº¦å’Œç¡¬åº¦æµ‹è¯•CMAè®¤è¯å®éªŒå®¤ä»·æ ¼",
            "å¡‘æ–™åˆ¶å“è€åŒ–æ€§èƒ½å’ŒåŒ–å­¦æˆåˆ†åˆ†æCNASè®¤å¯æœºæ„",
            "ç¯å¢ƒåœŸå£¤é‡é‡‘å±æ±¡æŸ“ç‰©æ£€æµ‹å‘¨æœŸå’Œæ ‡å‡†è¦æ±‚"
        ]
    }
    
    methods = [
        ("è¯­ä¹‰æœç´¢", lambda q: retrieval_engine.semantic_search(q, top_k=10)),
        ("æ··åˆæœç´¢", lambda q: retrieval_engine.hybrid_search(q, top_k=10)),
        ("æ™ºèƒ½æœç´¢", lambda q: retrieval_engine.smart_search(q, top_k=10))
    ]
    
    results = {}
    
    for complexity, queries in benchmark_queries.items():
        print(f"\n{complexity}:")
        results[complexity] = {}
        
        for method_name, method_func in methods:
            times = []
            result_counts = []
            
            for query in queries:
                start_time = time.time()
                search_results = method_func(query)
                duration = time.time() - start_time
                
                times.append(duration)
                result_counts.append(len(search_results))
            
            avg_time = sum(times) / len(times)
            avg_results = sum(result_counts) / len(result_counts)
            
            results[complexity][method_name] = {
                'avg_time': avg_time,
                'avg_results': avg_results
            }
            
            print(f"  {method_name}: å¹³å‡æ—¶é—´={avg_time:.3f}ç§’, å¹³å‡ç»“æœæ•°={avg_results:.1f}")
    
    return results

def save_test_results(results: Dict[str, Any], output_path: str = "retrieval_test_results.json"):
    """ä¿å­˜æµ‹è¯•ç»“æœ"""
    try:
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"\nâœ… æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
    except Exception as e:
        print(f"\nâŒ ä¿å­˜æµ‹è¯•ç»“æœå¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” æ£€ç´¢æ¨¡å—åŠŸèƒ½æ¼”ç¤º")
    print("=" * 60)
    
    try:
        # 1. æµ‹è¯•æŸ¥è¯¢å¤„ç†
        test_query_processing()
        
        # 2. åˆå§‹åŒ–æ£€ç´¢å¼•æ“
        print("\n=== åˆå§‹åŒ–æ£€ç´¢å¼•æ“ ===")
        
        # æ£€æŸ¥å‘é‡å­˜å‚¨æ˜¯å¦å­˜åœ¨
        if not Path(VECTOR_STORE_PATH).exists():
            print("âŒ å‘é‡å­˜å‚¨ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ run_vector_store.py")
            return
        
        # åˆå§‹åŒ–ç»„ä»¶
        print("åŠ è½½å‘é‡å­˜å‚¨...")
        vector_store = VectorStoreManager(
            store_type=VECTOR_STORE_TYPE,
            store_path=str(VECTOR_STORE_PATH)
        )
        
        print("åˆå§‹åŒ–åµŒå…¥å¼•æ“...")
        embedding_engine = EmbeddingEngine()
        
        print("åˆå§‹åŒ–æ£€ç´¢å¼•æ“...")
        retrieval_engine = RetrievalEngine(vector_store, embedding_engine)
        
        # è·å–å‘é‡å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯
        stats = vector_store.get_statistics()
        print(f"å‘é‡å­˜å‚¨ç»Ÿè®¡:")
        print(f"  æ–‡æ¡£æ€»æ•°: {stats.total_documents}")
        print(f"  åµŒå…¥ç»´åº¦: {stats.embedding_dimension}")
        print(f"  å­˜å‚¨ç±»å‹: {stats.storage_type}")
        print(f"  å­˜å‚¨å¤§å°: {stats.storage_size_mb:.2f} MB")
        
        # 3. è¿è¡Œå„ç§æµ‹è¯•
        test_semantic_search(retrieval_engine)
        test_hybrid_search(retrieval_engine)
        test_filtered_search(retrieval_engine)
        test_multi_query_search(retrieval_engine)
        test_smart_search(retrieval_engine)
        
        # 4. æ€§èƒ½åŸºå‡†æµ‹è¯•
        benchmark_results = benchmark_retrieval_performance(retrieval_engine)
        
        # 5. æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        print("\n=== æ£€ç´¢å¼•æ“ç»Ÿè®¡ä¿¡æ¯ ===")
        retrieval_stats = retrieval_engine.get_statistics()
        print(f"æ€»æŸ¥è¯¢æ•°: {retrieval_stats.query_count}")
        print(f"å¹³å‡å“åº”æ—¶é—´: {retrieval_stats.avg_response_time:.4f}ç§’")
        print(f"æœç´¢æ–‡æ¡£æ€»æ•°: {retrieval_stats.total_documents_searched}")
        
        # 6. ä¿å­˜æµ‹è¯•ç»“æœ
        all_results = {
            "timestamp": time.time(),
            "vector_store_stats": {
                "total_documents": stats.total_documents,
                "embedding_dimension": stats.embedding_dimension,
                "storage_type": stats.storage_type,
                "storage_size_mb": stats.storage_size_mb
            },
            "retrieval_stats": {
                "query_count": retrieval_stats.query_count,
                "avg_response_time": retrieval_stats.avg_response_time,
                "total_documents_searched": retrieval_stats.total_documents_searched
            },
            "benchmark_results": benchmark_results
        }
        
        save_test_results(all_results)
        
        print("\nâœ… æ£€ç´¢æ¨¡å—æµ‹è¯•å®Œæˆï¼")
        print("\nğŸ¯ æ£€ç´¢æ¨¡å—ä¸»è¦åŠŸèƒ½:")
        print("  âœ“ è¯­ä¹‰ç›¸ä¼¼åº¦æœç´¢")
        print("  âœ“ æ··åˆæœç´¢ï¼ˆè¯­ä¹‰+å…³é”®è¯ï¼‰") 
        print("  âœ“ è¿‡æ»¤æœç´¢ï¼ˆå…ƒæ•°æ®è¿‡æ»¤ï¼‰")
        print("  âœ“ å¤šæŸ¥è¯¢èåˆæœç´¢")
        print("  âœ“ æ™ºèƒ½æœç´¢ï¼ˆè‡ªåŠ¨ç­–ç•¥é€‰æ‹©ï¼‰")
        print("  âœ“ æŸ¥è¯¢é¢„å¤„ç†å’Œåˆ†æ")
        print("  âœ“ æ€§èƒ½ç›‘æ§å’Œç»Ÿè®¡")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 