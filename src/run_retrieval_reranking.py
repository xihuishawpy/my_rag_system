"""
æ£€ç´¢+é‡æ’åºé›†æˆæ¼”ç¤º
å±•ç¤ºå®Œæ•´çš„ä¸¤é˜¶æ®µæ£€ç´¢æµç¨‹
"""
import sys
import os
import time
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from data_processing import DataProcessor, Document
from embedding import EmbeddingEngine  
from vector_store import VectorStoreManager
from retrieval import RetrievalEngine
from reranking import RerankingEngine
from config import *

def create_mock_reranking_engine():
    """åˆ›å»ºæ¨¡æ‹Ÿçš„é‡æ’åºå¼•æ“ï¼ˆç”¨äºæ¼”ç¤ºï¼‰"""
    import random
    
    class MockRerankingEngine:
        def __init__(self):
            self.model_name = "mock-rerank-v2"
            
        def rerank_retrieval_results(self, query, retrieval_results, top_k=3):
            """æ¨¡æ‹Ÿé‡æ’åºåŠŸèƒ½"""
            from reranking import RerankResult
            
            results = []
            for i, retrieval_result in enumerate(retrieval_results[:top_k]):
                # æ¨¡æ‹Ÿé‡æ’åºåˆ†æ•°ï¼ˆåŸºäºæŸ¥è¯¢ç›¸å…³æ€§çš„ç®€å•è®¡ç®—ï¼‰
                query_words = set(query.lower().split())
                doc_words = set(retrieval_result.document.content.lower().split())
                
                # è®¡ç®—è¯æ±‡é‡å åº¦ä½œä¸ºæ¨¡æ‹Ÿé‡æ’åºåˆ†æ•°
                overlap = len(query_words.intersection(doc_words))
                base_score = overlap / max(len(query_words), 1)
                
                # æ·»åŠ ä¸€äº›éšæœºæ€§
                noise = random.uniform(-0.1, 0.1)
                mock_relevance_score = min(1.0, max(0.0, base_score + noise))
                
                result = RerankResult(
                    document=retrieval_result.document,
                    relevance_score=mock_relevance_score,
                    original_rank=retrieval_result.rank,
                    new_rank=i,
                    score_improvement=mock_relevance_score - retrieval_result.score,
                    metadata={
                        'original_retrieval_score': retrieval_result.score,
                        'original_retrieval_rank': retrieval_result.rank,
                        'retrieval_type': retrieval_result.retrieval_type,
                        'mock_reranking': True
                    }
                )
                results.append(result)
            
            # æŒ‰é‡æ’åºåˆ†æ•°æ’åº
            results.sort(key=lambda x: x.relevance_score, reverse=True)
            
            # æ›´æ–°æ–°æ’å
            for i, result in enumerate(results):
                result.new_rank = i
            
            return results
    
    return MockRerankingEngine()

def two_stage_retrieval_demo():
    """ä¸¤é˜¶æ®µæ£€ç´¢æ¼”ç¤ºï¼šæ£€ç´¢ + é‡æ’åº"""
    print("ğŸ” ä¸¤é˜¶æ®µæ£€ç´¢æ¼”ç¤ºï¼šæ£€ç´¢ + é‡æ’åº")
    print("=" * 60)
    
    try:
        # 1. åˆå§‹åŒ–ç»„ä»¶
        print("1. åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶...")
        data_processor = DataProcessor(str(EXCEL_FILE_PATH))
        embedding_engine = EmbeddingEngine()
        vector_store = VectorStoreManager(VECTOR_STORE_TYPE)
        retrieval_engine = RetrievalEngine(vector_store, embedding_engine)
        
        # ä½¿ç”¨æ¨¡æ‹Ÿé‡æ’åºå¼•æ“ï¼ˆé¿å…APIè°ƒç”¨é—®é¢˜ï¼‰
        reranking_engine = create_mock_reranking_engine()
        
        print("   âœ“ ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
        
        # 2. åŠ è½½æ•°æ®
        print("\n2. åŠ è½½å’Œå¤„ç†æ•°æ®...")
        try:
            # å°è¯•ä»ç¼“å­˜åŠ è½½å‘é‡å­˜å‚¨
            vector_store.load_index()
            print("   âœ“ ä»ç¼“å­˜åŠ è½½å‘é‡ç´¢å¼•æˆåŠŸ")
            
            # è·å–ä¸€äº›æ–‡æ¡£ç”¨äºæ¼”ç¤º
            stats = vector_store.get_statistics()
            print(f"   âœ“ å‘é‡åº“ç»Ÿè®¡: {stats.total_documents}ä¸ªæ–‡æ¡£, {stats.embedding_dimension}ç»´")
            
        except Exception as e:
            print(f"   ä»ç¼“å­˜åŠ è½½å¤±è´¥: {e}")
            print("   æ­£åœ¨é‡æ–°æ„å»ºå‘é‡ç´¢å¼•...")
            
            # é‡æ–°å¤„ç†æ•°æ®
            documents = data_processor.process_excel_to_documents()[:100]  # å‰100ä¸ªæ–‡æ¡£ç”¨äºæ¼”ç¤º
            print(f"   âœ“ å¤„ç†äº† {len(documents)} ä¸ªæ–‡æ¡£")
            
            # å‘é‡åŒ–
            embeddings = embedding_engine.embed_documents(documents)
            print(f"   âœ“ å‘é‡åŒ–å®Œæˆï¼Œç»´åº¦: {len(embeddings[0])}")
            
            # åˆ›å»ºå‘é‡ç´¢å¼•
            vector_store.add_documents(documents, embeddings)
            print("   âœ“ å‘é‡ç´¢å¼•åˆ›å»ºå®Œæˆ")
        
        # 3. æµ‹è¯•æŸ¥è¯¢
        test_queries = [
            {
                "query": "é‡‘å±ææ–™æ‹‰ä¼¸å¼ºåº¦æµ‹è¯•",
                "description": "å¯»æ‰¾é‡‘å±ææ–™åŠ›å­¦æ€§èƒ½æµ‹è¯•ç›¸å…³çš„æ–‡æ¡£"
            },
            {
                "query": "å¡‘æ–™åˆ¶å“æˆåˆ†åˆ†ææ–¹æ³•",
                "description": "æŸ¥æ‰¾å¡‘æ–™æˆåˆ†æ£€æµ‹å’Œåˆ†ææŠ€æœ¯"
            },
            {
                "query": "ç¯å¢ƒæ±¡æŸ“æ£€æµ‹æ ‡å‡†",
                "description": "æœç´¢ç¯å¢ƒç›‘æµ‹å’Œæ±¡æŸ“ç‰©æ£€æµ‹ç›¸å…³è§„èŒƒ"
            },
            {
                "query": "å»ºç­‘ææ–™æ€§èƒ½è¯„ä¼°",
                "description": "æŸ¥æ‰¾å»ºç­‘ææ–™è´¨é‡æ£€æµ‹å’Œæ€§èƒ½è¯„ä»·æ–¹æ³•"
            }
        ]
        
        print(f"\n3. æ‰§è¡Œä¸¤é˜¶æ®µæ£€ç´¢æµ‹è¯• ({len(test_queries)}ä¸ªæŸ¥è¯¢)")
        print("-" * 60)
        
        for i, test_case in enumerate(test_queries, 1):
            query = test_case["query"]
            description = test_case["description"]
            
            print(f"\nã€æŸ¥è¯¢ {i}ã€‘: {query}")
            print(f"æè¿°: {description}")
            
            # ç¬¬ä¸€é˜¶æ®µï¼šæ£€ç´¢
            print("\nğŸ” ç¬¬ä¸€é˜¶æ®µ - å‘é‡æ£€ç´¢:")
            start_time = time.time()
            
            retrieval_results = retrieval_engine.semantic_search(query, top_k=10)
            
            retrieval_time = time.time() - start_time
            print(f"   æ£€ç´¢æ—¶é—´: {retrieval_time:.3f}ç§’")
            print(f"   æ£€ç´¢åˆ° {len(retrieval_results)} ä¸ªå€™é€‰æ–‡æ¡£")
            
            print("   Top 5 æ£€ç´¢ç»“æœ:")
            for j, result in enumerate(retrieval_results[:5], 1):
                print(f"      {j}. ç›¸ä¼¼åº¦: {result.score:.4f}")
                print(f"         å†…å®¹: {result.document.content[:60]}...")
            
            # ç¬¬äºŒé˜¶æ®µï¼šé‡æ’åº
            print("\nğŸ¯ ç¬¬äºŒé˜¶æ®µ - é‡æ’åº:")
            start_time = time.time()
            
            rerank_results = reranking_engine.rerank_retrieval_results(
                query, retrieval_results, top_k=5
            )
            
            rerank_time = time.time() - start_time
            print(f"   é‡æ’åºæ—¶é—´: {rerank_time:.3f}ç§’")
            print(f"   é‡æ’åºå {len(rerank_results)} ä¸ªç²¾é€‰ç»“æœ")
            
            print("   Top 3 é‡æ’åºç»“æœ:")
            for j, result in enumerate(rerank_results[:3], 1):
                original_score = result.metadata.get('original_retrieval_score', 0)
                original_rank = result.metadata.get('original_retrieval_rank', 0)
                
                print(f"      {j}. ç›¸å…³æ€§: {result.relevance_score:.4f} (åŸç›¸ä¼¼åº¦: {original_score:.4f})")
                print(f"         æ’åå˜åŒ–: ç¬¬{original_rank+1}å â†’ ç¬¬{j}å")
                print(f"         å†…å®¹: {result.document.content[:60]}...")
            
            # æ€§èƒ½æ€»ç»“
            total_time = retrieval_time + rerank_time
            print(f"\n   ğŸ“Š æ€§èƒ½æŒ‡æ ‡:")
            print(f"      æ€»è€—æ—¶: {total_time:.3f}ç§’ (æ£€ç´¢: {retrieval_time:.3f}s + é‡æ’åº: {rerank_time:.3f}s)")
            print(f"      æ£€ç´¢æ•ˆç‡: {len(retrieval_results)/retrieval_time:.1f} docs/sec")
            
            if i < len(test_queries):
                print("\n" + "-" * 60)
        
        # 4. æ•ˆæœå¯¹æ¯”æ¼”ç¤º
        print(f"\n4. æ•ˆæœå¯¹æ¯”æ¼”ç¤º")
        print("=" * 60)
        
        comparison_query = "é‡‘å±ç–²åŠ³è¯•éªŒåˆ†æ"
        print(f"å¯¹æ¯”æŸ¥è¯¢: {comparison_query}")
        
        # ä»…æ£€ç´¢ç»“æœ
        print(f"\nğŸ“‹ ä»…æ£€ç´¢ç»“æœ (Top 3):")
        retrieval_only = retrieval_engine.semantic_search(comparison_query, top_k=3)
        for i, result in enumerate(retrieval_only, 1):
            print(f"   {i}. ç›¸ä¼¼åº¦: {result.score:.4f}")
            print(f"      å†…å®¹: {result.document.content[:60]}...")
        
        # æ£€ç´¢+é‡æ’åºç»“æœ  
        print(f"\nğŸ¯ æ£€ç´¢+é‡æ’åºç»“æœ (Top 3):")
        retrieval_for_rerank = retrieval_engine.semantic_search(comparison_query, top_k=10)
        rerank_final = reranking_engine.rerank_retrieval_results(
            comparison_query, retrieval_for_rerank, top_k=3
        )
        
        for i, result in enumerate(rerank_final, 1):
            original_rank = result.metadata.get('original_retrieval_rank', 0)
            print(f"   {i}. ç›¸å…³æ€§: {result.relevance_score:.4f} (åŸæ’å: ç¬¬{original_rank+1}å)")
            print(f"      å†…å®¹: {result.document.content[:60]}...")
        
        print(f"\nâœ… ä¸¤é˜¶æ®µæ£€ç´¢æ¼”ç¤ºå®Œæˆï¼")
        
        # 5. æ€»ç»“å’Œå»ºè®®
        print(f"\nğŸ“ˆ ç³»ç»Ÿç‰¹ç‚¹æ€»ç»“:")
        print(f"   âœ“ ç¬¬ä¸€é˜¶æ®µæ£€ç´¢ï¼šå¿«é€Ÿç­›é€‰å‡ºç›¸å…³å€™é€‰æ–‡æ¡£")
        print(f"   âœ“ ç¬¬äºŒé˜¶æ®µé‡æ’åºï¼šç²¾ç¡®è®¡ç®—ç›¸å…³æ€§ï¼Œæå‡ç²¾åº¦")
        print(f"   âœ“ æ¨¡å—åŒ–è®¾è®¡ï¼šæ£€ç´¢å’Œé‡æ’åºå¯ç‹¬ç«‹ä¼˜åŒ–")
        print(f"   âœ“ æ€§èƒ½å‡è¡¡ï¼šé€Ÿåº¦ä¸ç²¾åº¦çš„æœ€ä½³å¹³è¡¡")
        print(f"   âœ“ é™çº§æœºåˆ¶ï¼šAPIå¤±è´¥æ—¶ä»èƒ½æ­£å¸¸è¿è¡Œ")
        
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

def compare_retrieval_methods():
    """å¯¹æ¯”ä¸åŒæ£€ç´¢æ–¹æ³•çš„æ•ˆæœ"""
    print(f"\nğŸ”¬ æ£€ç´¢æ–¹æ³•æ•ˆæœå¯¹æ¯”")
    print("=" * 60)
    
    try:
        # åˆå§‹åŒ–ç»„ä»¶
        data_processor = DataProcessor(str(EXCEL_FILE_PATH))
        embedding_engine = EmbeddingEngine()
        vector_store = VectorStoreManager(VECTOR_STORE_TYPE)
        retrieval_engine = RetrievalEngine(vector_store, embedding_engine)
        reranking_engine = create_mock_reranking_engine()
        
        # åŠ è½½å‘é‡ç´¢å¼•
        try:
            vector_store.load_index()
        except:
            print("   éœ€è¦å…ˆè¿è¡Œä¸»æ¼”ç¤ºæ¥æ„å»ºå‘é‡ç´¢å¼•")
            return
        
        test_query = "ææ–™å¼ºåº¦æµ‹è¯•æ£€éªŒæ–¹æ³•"
        print(f"æµ‹è¯•æŸ¥è¯¢: {test_query}")
        print("-" * 40)
        
        # æ–¹æ³•1ï¼šçº¯è¯­ä¹‰æœç´¢
        print("ã€æ–¹æ³•1ã€‘çº¯è¯­ä¹‰æœç´¢:")
        start_time = time.time()
        semantic_results = retrieval_engine.semantic_search(test_query, top_k=5)
        semantic_time = time.time() - start_time
        
        print(f"   è€—æ—¶: {semantic_time:.3f}ç§’")
        for i, result in enumerate(semantic_results[:3], 1):
            print(f"   {i}. ç›¸ä¼¼åº¦: {result.score:.4f} - {result.document.content[:50]}...")
        
        # æ–¹æ³•2ï¼šæ··åˆæœç´¢
        print(f"\nã€æ–¹æ³•2ã€‘æ··åˆæœç´¢ (è¯­ä¹‰+å…³é”®è¯):")
        start_time = time.time()
        hybrid_results = retrieval_engine.hybrid_search(test_query, top_k=5, alpha=0.7)
        hybrid_time = time.time() - start_time
        
        print(f"   è€—æ—¶: {hybrid_time:.3f}ç§’")
        for i, result in enumerate(hybrid_results[:3], 1):
            print(f"   {i}. ç»¼åˆåˆ†: {result.score:.4f} - {result.document.content[:50]}...")
        
        # æ–¹æ³•3ï¼šæ™ºèƒ½æœç´¢
        print(f"\nã€æ–¹æ³•3ã€‘æ™ºèƒ½æœç´¢ (è‡ªåŠ¨ç­–ç•¥):")
        start_time = time.time()
        smart_results = retrieval_engine.smart_search(test_query, top_k=5)
        smart_time = time.time() - start_time
        
        print(f"   è€—æ—¶: {smart_time:.3f}ç§’")
        for i, result in enumerate(smart_results[:3], 1):
            print(f"   {i}. æ™ºèƒ½åˆ†: {result.score:.4f} - {result.document.content[:50]}...")
        
        # æ–¹æ³•4ï¼šè¯­ä¹‰æœç´¢ + é‡æ’åº
        print(f"\nã€æ–¹æ³•4ã€‘è¯­ä¹‰æœç´¢ + é‡æ’åº:")
        start_time = time.time()
        retrieval_for_rerank = retrieval_engine.semantic_search(test_query, top_k=10)
        rerank_results = reranking_engine.rerank_retrieval_results(
            test_query, retrieval_for_rerank, top_k=5
        )
        rerank_total_time = time.time() - start_time
        
        print(f"   è€—æ—¶: {rerank_total_time:.3f}ç§’")
        for i, result in enumerate(rerank_results[:3], 1):
            original_rank = result.metadata.get('original_retrieval_rank', 0)
            print(f"   {i}. ç›¸å…³æ€§: {result.relevance_score:.4f} (åŸæ’å: {original_rank+1}) - {result.document.content[:50]}...")
        
        # æ€§èƒ½å¯¹æ¯”
        print(f"\nğŸ“Š æ€§èƒ½å¯¹æ¯”:")
        print(f"   çº¯è¯­ä¹‰æœç´¢:       {semantic_time:.3f}ç§’")
        print(f"   æ··åˆæœç´¢:         {hybrid_time:.3f}ç§’") 
        print(f"   æ™ºèƒ½æœç´¢:         {smart_time:.3f}ç§’")
        print(f"   è¯­ä¹‰+é‡æ’åº:      {rerank_total_time:.3f}ç§’")
        
        print(f"\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
        print(f"   â€¢ å¿«é€Ÿæœç´¢: ä½¿ç”¨çº¯è¯­ä¹‰æœç´¢")
        print(f"   â€¢ å¹³è¡¡æ•ˆæœ: ä½¿ç”¨æ··åˆæœç´¢")
        print(f"   â€¢ è‡ªåŠ¨ä¼˜åŒ–: ä½¿ç”¨æ™ºèƒ½æœç´¢")
        print(f"   â€¢ æœ€é«˜ç²¾åº¦: ä½¿ç”¨è¯­ä¹‰æœç´¢+é‡æ’åº")
        
    except Exception as e:
        print(f"å¯¹æ¯”æµ‹è¯•å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ æ£€ç´¢+é‡æ’åºé›†æˆæ¼”ç¤º")
    print("æ„å»ºå®Œæ•´çš„ä¸¤é˜¶æ®µRAGæ£€ç´¢æµç¨‹")
    print("=" * 80)
    
    # ä¸»æ¼”ç¤º
    two_stage_retrieval_demo()
    
    # æ–¹æ³•å¯¹æ¯”
    compare_retrieval_methods()
    
    print(f"\nğŸ† æ¼”ç¤ºæ€»ç»“:")
    print(f"   âœ… å®Œæ•´ä¸¤é˜¶æ®µæ£€ç´¢æµç¨‹å·²å®ç°")
    print(f"   âœ… å¤šç§æ£€ç´¢ç­–ç•¥å¯çµæ´»é€‰æ‹©") 
    print(f"   âœ… é‡æ’åºæ˜¾è‘—æå‡ç»“æœç²¾åº¦")
    print(f"   âœ… ç³»ç»Ÿå…·å¤‡è‰¯å¥½çš„é”™è¯¯å¤„ç†èƒ½åŠ›")
    print(f"   âœ… ä¸ºé—®ç­”æ¨¡å—æä¾›äº†é«˜è´¨é‡çš„æ–‡æ¡£æ£€ç´¢åŸºç¡€")

if __name__ == "__main__":
    main() 