"""
å‘é‡å­˜å‚¨æ¨¡å—è¿è¡Œè„šæœ¬
æ¼”ç¤ºå‘é‡å­˜å‚¨çš„åŸºæœ¬åŠŸèƒ½
"""
import sys
import os
import numpy as np
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from vector_store import VectorStoreManager
from data_processing import DataProcessor
from embedding import EmbeddingEngine
from config import DATA_DIR, VECTOR_STORE_PATH, VECTOR_STORE_TYPE

def demo_vector_store():
    """æ¼”ç¤ºå‘é‡å­˜å‚¨åŠŸèƒ½"""
    print("=== å‘é‡å­˜å‚¨æ¨¡å—æ¼”ç¤º ===\n")
    
    try:
        # 1. åŠ è½½æ•°æ®
        print("1. åŠ è½½Excelæ•°æ®...")
        from config import EXCEL_FILE_PATH
        processor = DataProcessor(EXCEL_FILE_PATH)
        documents = processor.process_excel_to_documents()
        print(f"   å·²åŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£")
        
        # 2. åˆå§‹åŒ–åµŒå…¥å¼•æ“
        print("\n2. åˆå§‹åŒ–åµŒå…¥å¼•æ“...")
        embedding_engine = EmbeddingEngine()
        print("   åµŒå…¥å¼•æ“åˆå§‹åŒ–å®Œæˆ")
        
        # 3. ç”Ÿæˆæ–‡æ¡£åµŒå…¥
        print("\n3. ç”Ÿæˆæ–‡æ¡£åµŒå…¥...")
        embeddings = []
        batch_size = 10
        
        for i in range(0, len(documents), batch_size):
            batch_docs = documents[i:i+batch_size]
            batch_embeddings = embedding_engine.embed_documents(batch_docs)
            embeddings.extend(batch_embeddings)
            print(f"   å·²å¤„ç† {min(i+batch_size, len(documents))}/{len(documents)} ä¸ªæ–‡æ¡£")
        
        print(f"   åµŒå…¥ç»´åº¦: {len(embeddings[0]) if embeddings else 0}")
        
        # 4. åˆå§‹åŒ–å‘é‡å­˜å‚¨
        print("\n4. åˆå§‹åŒ–å‘é‡å­˜å‚¨...")
        vector_store = VectorStoreManager(
            store_type=VECTOR_STORE_TYPE,  
            store_path=str(VECTOR_STORE_PATH)
        )
        print("   å‘é‡å­˜å‚¨åˆå§‹åŒ–å®Œæˆ")
        
        # 5. åˆ›å»ºç´¢å¼•
        print("\n5. åˆ›å»ºå‘é‡ç´¢å¼•...")
        vector_store.create_index(documents, embeddings)
        print("   ç´¢å¼•åˆ›å»ºå®Œæˆ")
        
        # 6. è·å–ç»Ÿè®¡ä¿¡æ¯
        print("\n6. å‘é‡å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯:")
        stats = vector_store.get_statistics()
        print(f"   æ–‡æ¡£æ€»æ•°: {stats.total_documents}")
        print(f"   åµŒå…¥ç»´åº¦: {stats.embedding_dimension}")
        print(f"   å­˜å‚¨ç±»å‹: {stats.storage_type}")
        print(f"   å­˜å‚¨å¤§å°: {stats.storage_size_mb:.2f} MB")
        
        # 7. æœç´¢æµ‹è¯•
        print("\n7. æœç´¢åŠŸèƒ½æµ‹è¯•:")
        test_queries = [
            "ææ–™åˆ†ææµ‹è¯•",
            "æ€§èƒ½æ£€æµ‹æ–¹æ³•",
            "è´¨é‡æ§åˆ¶æ ‡å‡†",
            "ç¯å¢ƒæµ‹è¯•æ¡ä»¶"
        ]
        
        for query in test_queries:
            print(f"\n   æŸ¥è¯¢: {query}")
            
            # ç”ŸæˆæŸ¥è¯¢åµŒå…¥
            query_embedding = embedding_engine.embed_query(query)
            
            # æœç´¢ç›¸ä¼¼æ–‡æ¡£
            results = vector_store.search(query_embedding, top_k=3)
            
            print(f"   æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³æ–‡æ¡£:")
            for i, result in enumerate(results):
                content_preview = result.document.content[:50] + "..." if len(result.document.content) > 50 else result.document.content
                print(f"     {i+1}. {content_preview} (ç›¸ä¼¼åº¦: {result.score:.4f})")
        
        # 8. æµ‹è¯•å…ƒæ•°æ®è¿‡æ»¤æœç´¢ï¼ˆå¦‚æœæ”¯æŒï¼‰
        print("\n8. å…ƒæ•°æ®è¿‡æ»¤æœç´¢æµ‹è¯•:")
        try:
            # è·å–ç¬¬ä¸€ä¸ªæŸ¥è¯¢çš„åµŒå…¥
            query_embedding = embedding_engine.embed_query("ææ–™æµ‹è¯•")
            
            # å¦‚æœæ–‡æ¡£æœ‰å…ƒæ•°æ®ï¼Œå°è¯•è¿‡æ»¤æœç´¢
            if documents and documents[0].metadata:
                # è·å–å¯ç”¨çš„å…ƒæ•°æ®é”®
                metadata_keys = list(documents[0].metadata.keys())
                print(f"   å¯ç”¨å…ƒæ•°æ®å­—æ®µ: {metadata_keys}")
                
                # å°è¯•æŒ‰ç¬¬ä¸€ä¸ªå…ƒæ•°æ®å­—æ®µè¿‡æ»¤
                if metadata_keys:
                    first_key = metadata_keys[0]
                    first_value = documents[0].metadata[first_key]
                    
                    # æ³¨æ„ï¼šChromaDBå’ŒFAISSçš„è¿‡æ»¤è¯­æ³•å¯èƒ½ä¸åŒ
                    if hasattr(vector_store.store, 'collection'):  # ChromaDB
                        results = vector_store.search(
                            query_embedding, 
                            top_k=5,
                            where={first_key: first_value}
                        )
                        print(f"   æŒ‰ {first_key}={first_value} è¿‡æ»¤ï¼Œæ‰¾åˆ° {len(results)} ä¸ªæ–‡æ¡£")
                    else:
                        print("   å½“å‰å­˜å‚¨åç«¯ä¸æ”¯æŒå…ƒæ•°æ®è¿‡æ»¤æœç´¢")
            else:
                print("   æ–‡æ¡£æ²¡æœ‰å…ƒæ•°æ®ï¼Œè·³è¿‡è¿‡æ»¤æœç´¢æµ‹è¯•")
                
        except Exception as e:
            print(f"   å…ƒæ•°æ®è¿‡æ»¤æœç´¢å¤±è´¥: {e}")
        
        # 9. ä¿å­˜ç´¢å¼•
        print("\n9. ä¿å­˜å‘é‡ç´¢å¼•...")
        vector_store.save_index()
        print("   ç´¢å¼•ä¿å­˜å®Œæˆ")
        
        print("\nâœ… å‘é‡å­˜å‚¨æ¨¡å—æ¼”ç¤ºå®Œæˆï¼")
        print(f"\nğŸ’¾ å‘é‡æ•°æ®åº“å·²ä¿å­˜åˆ°: {VECTOR_STORE_PATH}")
        print("ğŸ“ æ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼ä½¿ç”¨å‘é‡å­˜å‚¨:")
        print("   1. åŠ è½½ç°æœ‰ç´¢å¼•è¿›è¡Œæœç´¢")
        print("   2. æ·»åŠ æ–°æ–‡æ¡£åˆ°ç°æœ‰ç´¢å¼•")
        print("   3. æ›´æ–°æˆ–åˆ é™¤ç‰¹å®šæ–‡æ¡£")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_vector_store_operations():
    """æµ‹è¯•å‘é‡å­˜å‚¨çš„å„ç§æ“ä½œ"""
    print("\n=== å‘é‡å­˜å‚¨æ“ä½œæµ‹è¯• ===\n")
    
    try:
        # åˆ›å»ºæµ‹è¯•æ–‡æ¡£
        from data_processing import Document
        
        test_documents = [
            Document("ææ–™å¼ºåº¦æµ‹è¯•æ ‡å‡†", {"type": "standard", "category": "strength"}, "test_001"),
            Document("åŒ–å­¦æˆåˆ†åˆ†ææ–¹æ³•", {"type": "method", "category": "chemistry"}, "test_002"),
            Document("ç‰©ç†æ€§èƒ½æ£€æµ‹æµç¨‹", {"type": "process", "category": "physics"}, "test_003"),
        ]
        
        # åˆ›å»ºæµ‹è¯•åµŒå…¥
        test_embeddings = [
            np.random.rand(384).astype(np.float32),  # æ¨¡æ‹ŸåµŒå…¥å‘é‡
            np.random.rand(384).astype(np.float32),
            np.random.rand(384).astype(np.float32),
        ]
        
        # åˆå§‹åŒ–å‘é‡å­˜å‚¨
        vector_store = VectorStoreManager(
            store_type="faiss",  # ä½¿ç”¨FAISSè¿›è¡Œæ“ä½œæµ‹è¯•
            store_path="test_operations"
        )
        
        # åˆ›å»ºç´¢å¼•
        print("1. åˆ›å»ºæµ‹è¯•ç´¢å¼•...")
        vector_store.create_index(test_documents, test_embeddings)
        print("   ç´¢å¼•åˆ›å»ºå®Œæˆ")
        
        # æ·»åŠ æ–‡æ¡£
        print("\n2. æ·»åŠ æ–°æ–‡æ¡£...")
        new_doc = Document("ç¯å¢ƒæµ‹è¯•æ¡ä»¶æ ‡å‡†", {"type": "standard", "category": "environment"}, "test_004")
        new_embedding = np.random.rand(384).astype(np.float32)
        vector_store.add_documents([new_doc], [new_embedding])
        print("   æ–‡æ¡£æ·»åŠ å®Œæˆ")
        
        # æœç´¢æµ‹è¯•
        print("\n3. æœç´¢æµ‹è¯•...")
        query_embedding = np.random.rand(384).astype(np.float32)
        results = vector_store.search(query_embedding, top_k=2)
        print(f"   æ‰¾åˆ° {len(results)} ä¸ªç»“æœ")
        
        # æ›´æ–°æ–‡æ¡£
        print("\n4. æ›´æ–°æ–‡æ¡£...")
        updated_doc = Document("æ›´æ–°åçš„ææ–™å¼ºåº¦æµ‹è¯•æ ‡å‡†", {"type": "standard", "category": "strength", "version": "2.0"}, "test_001")
        updated_embedding = np.random.rand(384).astype(np.float32)
        success = vector_store.update_document("test_001", updated_doc, updated_embedding)
        print(f"   æ›´æ–°ç»“æœ: {'æˆåŠŸ' if success else 'å¤±è´¥'}")
        
        # åˆ é™¤æ–‡æ¡£
        print("\n5. åˆ é™¤æ–‡æ¡£...")
        success = vector_store.delete_document("test_003")
        print(f"   åˆ é™¤ç»“æœ: {'æˆåŠŸ' if success else 'å¤±è´¥'}")
        
        # æœ€ç»ˆç»Ÿè®¡
        stats = vector_store.get_statistics()
        print(f"\n6. æœ€ç»ˆç»Ÿè®¡: {stats.total_documents} ä¸ªæ–‡æ¡£")
        
        # æ¸…ç†
        import shutil
        if Path("test_operations").exists():
            shutil.rmtree("test_operations")
            print("   æµ‹è¯•æ–‡ä»¶å·²æ¸…ç†")
        
        print("\nâœ… æ“ä½œæµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"\nâŒ æ“ä½œæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    # è¿è¡Œæ¼”ç¤º
    success = demo_vector_store()
    
    if success:
        # è¿è¡Œæ“ä½œæµ‹è¯•
        test_vector_store_operations() 